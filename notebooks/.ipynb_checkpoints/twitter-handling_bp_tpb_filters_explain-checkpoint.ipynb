{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering tweets for Tracking Pandemic Borderscapes\n",
    "\n",
    "This document explains how the tweets are filtered and selected from the collection of tweets from various news outlets.\n",
    "\n",
    "We use Python for most data management tasks - including filtering - so this document will include a lot of Python code. I will explain the parts of the code essential to understanding the filtering but will not go into details about the rest of the code as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data\n",
    "\n",
    "The code below reads in all of the tweets from the news outlets. 423.803 tweets are collected in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:04:12.129943Z",
     "iopub.status.busy": "2022-03-10T15:04:12.129408Z",
     "iopub.status.idle": "2022-03-10T15:04:46.914647Z",
     "shell.execute_reply": "2022-03-10T15:04:46.913833Z",
     "shell.execute_reply.started": "2022-03-10T15:04:12.129887Z"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import ast \n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "# load data\n",
    "with open('../data/tpb_tweets_news-outlets_20211208.json', \"r\") as outfile:\n",
    "    all_data = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:04:59.188653Z",
     "iopub.status.busy": "2022-03-10T15:04:59.188503Z",
     "iopub.status.idle": "2022-03-10T15:04:59.192561Z",
     "shell.execute_reply": "2022-03-10T15:04:59.192042Z",
     "shell.execute_reply.started": "2022-03-10T15:04:59.188633Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423803"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data.get(\"data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating filters\n",
    "\n",
    "We are using so-called \"regular expressions\" to filter the data. Regular expressions are special text lines that uses special character to match specific text patterns, words, sentences and so on.\n",
    "\n",
    "Similar to how we are able to use \"wildcards\" in literature search (using a \\*) and using operators like AND and OR or something similar, regular expressions can be written to match certain criteria in texts.\n",
    "\n",
    "In this case, we are using regular expressions to create different filters. We are currently working with three filters:\n",
    "- A covid filter: Matches the words related to the pandemic - either if used in the tweet text or as a hashtag in the tweet\n",
    "- An migration filter: Matches the words related to migration - either if used in the tweet text or as a hashtag in the tweet\n",
    "- A geography filter: Matches the words related to the geographies - either if used in the tweet text or as a hashtag in the tweet\n",
    "\n",
    "Each filter has the condition that *one* of the words in the filter has to be present in the tweet when used. \n",
    "\n",
    "\n",
    "### Using regular expressions as filters\n",
    "\n",
    "When writing filters like this, we want to make sure that we capture spelling variations of the same word (fx \"boat\" and \"boats\") while avoiding irrelevant words containing the same sequence of characters (fx \"boat\" and \"showboat\"). It is very difficult to be 100% precise because it sometimes depends on the context whether the word in question is actually the word of interest (fx differentiating between \"corona\" used in relation to the virus and \"corona\" used in relation to the beer).\n",
    "\n",
    "In these filters we use regular expressions for two things:\n",
    "- Setting up word boundaries where relevant\n",
    "- Specifying that the filter should just match one of the words\n",
    "\n",
    "**Word boundaries**\n",
    "\n",
    "Regular expressions uses a variety of special characters to match text. `\\b` is a special character matching a word boundary; meaning that there has to be whitespace (space, newline, etc.) or puntuation. This is what we use to make sure we match \"boat\" and \"boats\" but not \"showboat\".\n",
    "\n",
    "In the example below, we are creating the regular expression \"boat\", and seeing what happens, when we use that on the text:\n",
    "\n",
    "> \"I do not mean to showboat but I have a pretty cool car with shiny rims.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:04:59.193321Z",
     "iopub.status.busy": "2022-03-10T15:04:59.193189Z",
     "iopub.status.idle": "2022-03-10T15:04:59.219040Z",
     "shell.execute_reply": "2022-03-10T15:04:59.217993Z",
     "shell.execute_reply.started": "2022-03-10T15:04:59.193306Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a match\n"
     ]
    }
   ],
   "source": [
    "text = \"I do not mean to showboat but I have a pretty cool car with shiny rims.\"\n",
    "regex_boats_nob = re.compile(r\"boat\")\n",
    "\n",
    "if regex_boats_nob.search(text):\n",
    "    print(\"It's a match\")\n",
    "else:\n",
    "    print(\"It's not a match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code returns \"it's a match\", meaning the filter matches the text.\n",
    "\n",
    "We avoid that by specifying a word boundary at the beginning of the word using the regular expression \"\\bboat\" instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:04:59.221457Z",
     "iopub.status.busy": "2022-03-10T15:04:59.221031Z",
     "iopub.status.idle": "2022-03-10T15:04:59.247542Z",
     "shell.execute_reply": "2022-03-10T15:04:59.246487Z",
     "shell.execute_reply.started": "2022-03-10T15:04:59.221409Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not a match\n"
     ]
    }
   ],
   "source": [
    "text = \"I do not mean to showboat but I have a pretty cool car with shiny rims.\"\n",
    "regex_boats_b = re.compile(r\"\\bboat\")\n",
    "\n",
    "if regex_boats_b.search(text):\n",
    "    print(\"It's a match\")\n",
    "else:\n",
    "    print(\"It's not a match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we told the filter to match a word boundary before \"boat\", it is no longer a match.\n",
    "\n",
    "To sum up using different regular expressions:\n",
    "- \"boat\" will match \"boat\", \"boats\" and \"showboats\"\n",
    "- \"\\bboat\" will match \"boat\" and \"boats\" (because of word boundary of left side)\n",
    "- \"\\bboat\\b\" will match \"boat\" (because of word boundaries on both left and right side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matching one of several words**\n",
    "\n",
    "The character `|` is used in regular expression to speciy an \"or\"-condition; meaning that it will match the text as long as one of the words separated by the `|` is present.\n",
    "\n",
    "The example below uses the regular expression \"Italy|Cyprus\" to look for either \"Italy\" or \"Cyprus\" in the sentence:\n",
    "\n",
    "> I do not get out of Scandinavia much but if I did, I would like to go to Cyprus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:04:59.249943Z",
     "iopub.status.busy": "2022-03-10T15:04:59.249420Z",
     "iopub.status.idle": "2022-03-10T15:04:59.289080Z",
     "shell.execute_reply": "2022-03-10T15:04:59.288045Z",
     "shell.execute_reply.started": "2022-03-10T15:04:59.249891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a match\n"
     ]
    }
   ],
   "source": [
    "text = \"I do not get out of Scandinavia much but if I did, I would like to go to Cyprus.\"\n",
    "regex_itacyp = re.compile(r\"Italy|Cyprus\")\n",
    "\n",
    "if regex_itacyp.search(text):\n",
    "    print(\"It's a match\")\n",
    "else:\n",
    "    print(\"It's not a match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The covid filter\n",
    "\n",
    "The covid filter matches one of the following (notice placement of word boundaries):\n",
    "- \\bpandemic\\b\n",
    "- \\bcovid\\b\n",
    "- \\bcovid-19\\b \n",
    "- \\bcorona\n",
    "- \\bvaccine\n",
    "- \\bquarantine\n",
    "\n",
    "### The migration filter\n",
    "\n",
    "The migration filter matches one of the following (notice placement of word boundaries):\n",
    "- \\bmigrant\n",
    "- \\brefugee\n",
    "- \\btransit\n",
    "- \\bdisplacement\\b\n",
    "- \\bborder\n",
    "- \\breturn\\b\n",
    "- \\bpushback\n",
    "- \\bboat\n",
    "- \\bdrowning\\b\n",
    "- \\bhunger\n",
    "\n",
    "### The geographies filter\n",
    "\n",
    "The migration filter matches one of the following (notice placement of word boundaries):\n",
    "- \\blebanon\\b\n",
    "- \\blebanese\\b\n",
    "- \\bsyria\n",
    "- \\bjordan\n",
    "- \\biraq\n",
    "- \\bgreece\\b\n",
    "- \\bgreek\n",
    "- \\bturkey\\b\n",
    "- \\bturkish\\b\n",
    "- \\bcyprus\\b\n",
    "- \\bcypriot\n",
    "- \\bmediterranean\\b\n",
    "- \\bEU\\b\n",
    "- \\btunisia\n",
    "- \\bitaly\\b\n",
    "- \\bitalian\\b\n",
    "- \\beuropean\\b\n",
    "\n",
    "## Code for creating the filters\n",
    "\n",
    "The code below creates te filters using regular expressions. The `re.IGNORECASE` parts of the codes tells the filter to match the word regardless of casing (both upper-case and lower-case are matched)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:31:23.575052Z",
     "iopub.status.busy": "2022-03-10T15:31:23.574515Z",
     "iopub.status.idle": "2022-03-10T15:31:23.582656Z",
     "shell.execute_reply": "2022-03-10T15:31:23.581859Z",
     "shell.execute_reply.started": "2022-03-10T15:31:23.574988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regex_string_covid = r\"\\bpandemic\\b|\\bcovid\\b|\\bcovid-19\\b|\\bcorona|\\bvaccine|\\bquarantine\"\n",
    "regex_string_migrations = r\"\\bmigrant|\\brefugee|\\btransit|\\bdisplacement\\b|\\bborder|\\breturn\\b|\\bpushback|\\bboat|\\bdrowning\\b|\\bhunger\"\n",
    "regex_string_geos = r\"\\blebanon\\b|\\blebanese\\b|\\bsyria|\\bjordan|\\biraq|\\bgreece\\b|\\bgreek|\\bturkey\\b|\\bturkish\\b|\\bcyprus\\b|\\bcypriot|\\bmediterranean\\b|\\bEU\\b|\\btunisia|\\bitaly\\b|\\bitalian\\b|\\beuropean\\b\"\n",
    "\n",
    "regex_covid = re.compile(regex_string_covid, re.IGNORECASE)\n",
    "regex_migrations = re.compile(regex_string_migrations, re.IGNORECASE)\n",
    "regex_geos = re.compile(regex_string_geos, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the filters\n",
    "\n",
    "The codes below applies various combinations of filters. Because the words are currently split into three filters, we can combine them in different ways either requiring all three filters match, two of the filters are matced or one of the filters are matched.\n",
    "\n",
    "Notice the line of code:\n",
    "\n",
    "```python\n",
    "if regex_covid.search(entry.get('text')) and regex_migrations.search(entry.get('text')) and regex_geos.search(entry.get('text'))\n",
    "```\n",
    "\n",
    "The blocks containing either `regex_covid`, `regex_migrations`, `regex_geos` refer to the different filters especially. The `and` specifies that both filters should be present. So because `and` is used between all three filters, all filters are applied. Other combinations uses `or` meaning one of the filters must match. A combination like \"filter1 *and* filter2 *or* filter3\" will require that filter1 is a match *and* either filter2 *or* filter3 matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All filters must match: 387 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:36:33.548421Z",
     "iopub.status.busy": "2022-03-10T15:36:33.548015Z",
     "iopub.status.idle": "2022-03-10T15:36:36.972972Z",
     "shell.execute_reply": "2022-03-10T15:36:36.972430Z",
     "shell.execute_reply.started": "2022-03-10T15:36:33.548381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## all filters\n",
    "data_filter_cig = []\n",
    "\n",
    "for entry in all_data.get('data'):\n",
    "    if regex_covid.search(entry.get('text')) and regex_migrations.search(entry.get('text')) and regex_geos.search(entry.get('text')):\n",
    "        data_filter_cig.append(entry)\n",
    "len(data_filter_cig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Migration and geographies: 3516 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:37:00.536992Z",
     "iopub.status.busy": "2022-03-10T15:37:00.536397Z",
     "iopub.status.idle": "2022-03-10T15:37:04.762085Z",
     "shell.execute_reply": "2022-03-10T15:37:04.761367Z",
     "shell.execute_reply.started": "2022-03-10T15:37:00.536931Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3516"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## migration and geos\n",
    "data_filter_ig = []\n",
    "\n",
    "for entry in all_data.get('data'):\n",
    "    if regex_migrations.search(entry.get('text')) and regex_geos.search(entry.get('text')):\n",
    "        data_filter_ig.append(entry)\n",
    "len(data_filter_ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Migration and covid: 1129 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T13:28:28.555873Z",
     "iopub.status.busy": "2022-02-28T13:28:28.555340Z",
     "iopub.status.idle": "2022-02-28T13:28:31.464277Z",
     "shell.execute_reply": "2022-02-28T13:28:31.463697Z",
     "shell.execute_reply.started": "2022-02-28T13:28:28.555804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## migration and covid\n",
    "data_filter_ci = []\n",
    "\n",
    "for entry in all_data.get('data'):\n",
    "    if regex_covid.search(entry.get('text')) and regex_migrations.search(entry.get('text')):\n",
    "        data_filter_ci.append(entry)\n",
    "len(data_filter_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Migration only: 13157 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:37:34.809931Z",
     "iopub.status.busy": "2022-03-10T15:37:34.809392Z",
     "iopub.status.idle": "2022-03-10T15:37:38.759354Z",
     "shell.execute_reply": "2022-03-10T15:37:38.758784Z",
     "shell.execute_reply.started": "2022-03-10T15:37:34.809876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13157"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## migration only\n",
    "data_filter_i = []\n",
    "\n",
    "for entry in all_data.get('data'):\n",
    "    if regex_migrations.search(entry.get('text')):\n",
    "        data_filter_i.append(entry)\n",
    "len(data_filter_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geographies only: 14197 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T15:38:00.102027Z",
     "iopub.status.busy": "2022-03-10T15:38:00.101460Z",
     "iopub.status.idle": "2022-03-10T15:38:07.811822Z",
     "shell.execute_reply": "2022-03-10T15:38:07.810006Z",
     "shell.execute_reply.started": "2022-03-10T15:38:00.101961Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22671"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## geos only\n",
    "data_filter_g = []\n",
    "\n",
    "for entry in all_data.get('data'):\n",
    "    if regex_geos.search(entry.get('text')):\n",
    "        data_filter_g.append(entry)\n",
    "len(data_filter_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Migration or geographies: 25234 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T13:30:01.758536Z",
     "iopub.status.busy": "2022-02-28T13:30:01.758024Z",
     "iopub.status.idle": "2022-02-28T13:30:11.250402Z",
     "shell.execute_reply": "2022-02-28T13:30:11.249626Z",
     "shell.execute_reply.started": "2022-02-28T13:30:01.758483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25234"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## migration or geo\n",
    "data_filter_iorg = []\n",
    "\n",
    "for entry in all_data.get('data'):\n",
    "    if regex_migrations.search(entry.get('text')) or regex_geos.search(entry.get('text')):\n",
    "        data_filter_iorg.append(entry)\n",
    "len(data_filter_iorg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**covid and migration or geographies: 2152 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T13:30:48.959523Z",
     "iopub.status.busy": "2022-02-28T13:30:48.959010Z",
     "iopub.status.idle": "2022-02-28T13:30:52.146738Z",
     "shell.execute_reply": "2022-02-28T13:30:52.146101Z",
     "shell.execute_reply.started": "2022-02-28T13:30:48.959469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2152"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## covid and migration or geo\n",
    "data_filter_ciorg = []\n",
    "\n",
    "for entry in all_data.get('data'):\n",
    "    if regex_covid.search(entry.get('text')) and (regex_migrations.search(entry.get('text')) or regex_geos.search(entry.get('text'))):\n",
    "        data_filter_ciorg.append(entry)\n",
    "len(data_filter_ciorg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8, tm",
   "language": "python",
   "name": "tmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
